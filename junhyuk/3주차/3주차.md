### [Statistics/Math]

* 조건부 확률은 무엇일까요?  

Keyword : 베이즈정리

사건 B가 일어나는 경우 사건 A가 일어날 확률을 말합니다. 사건 B가 일어나는 경우에 사건 A가 일어날 확률은 $P(B|A)$ 로 표기합니다. 사건 B가 발생했을때 사건 A가 발생할 확률은 사건 B의 영향을 받아 변하게 됩니다.

![](https://i.imgur.com/dArpdO6.png)

**베이즈 정리** : 어떤 사건이 서로 배반하는 원인 둘에 의해 일어난다고 할 때, 실제 사건이 일어났을 때 이것이 두 원인 중 하나일 확률을 구하는 정리를 **베이즈의 정리** 라고 합니다.

![](https://i.imgur.com/tvNI7sI.png)


* 공분산과 상관계수는 무엇일까요? 수식과 함께 표현해주세요.  

Keyword : 상관성

**공분산**이란 두 개의 확률변수의 선형적인 상관성의 정도를 나타내는 값입니다.

![](https://i.imgur.com/RuZBVnH.png)

두 변수가 양의 방향으로 선형적인 관계를 가진다면 공분산이 양의 값으로 커질 것이고, 음의 방향으로 선형적인 관계를 가진다면 공분산이 음의 값으로 커질 것이며, 상관성이 없다면 0에 가까워 집니다.

**상관계수**란 표준화된 두 변수의 공분산 값입니다.

![](https://i.imgur.com/z8n2l2Y.png)

상관계수는 두 변수의 공분산을 각 변수의 표준편차로 나눔으로써 표준화 효과를 가지게 됩니다. 1 또는 -1 에 가까울수록 상관성이 큰 것이고, 0에 가까울 수록 상관성이 작아집니다.

### [Deep Learning]

* 알고있는 Activation Function에 대해 알려주세요. (Sigmoid, ReLU, LeakyReLU, Tanh 등)  

Keyword : Sigmoid, ReLU, Tanh, ELU

1. **Sigmoid function** 은 Logistic 함수라고 불리기도 하며 미분이 되지않는 계단 함수를 미분 가능하도록 곡선화를 적용한 함수입니다.

    ![](https://i.imgur.com/CAPApz8.png)


2. **ReLU function(Rectified Linear Unit)** 이란 $f(x) = max(0,x)$ 함수로, 정의해보면 "어떤 $x$가 0보다 크면 $x$를 출력, 0보다 작으면 0으로 출력"하는 함수를 의미 합니다.

    ![](https://i.imgur.com/q9yS0mL.png)

3. **Leaky ReLU** 는 ReLU가 갖는 **Dying ReLU** 를 해결하기 위해 나온 함수입니다.

- Dying ReLU : 음의 값을 가지면 전부 0으로 출력하기 때문에 몇몇 weight들이 업데이트 되지 않는 현상

    ![](https://i.imgur.com/dyQ6UVQ.png)

4. **tanh function** 은 sigmoid function의 함수 값의 중간이 0이 아니라서 학습이 느리다는 단점을 극복한 함수입니다.

    ![](https://i.imgur.com/ua5y2m5.png)

5. **ELU(Exponential Linear Units)** 은 ReLU와 Leaky ReLU의 중간정도(?)입니다. ELU는 Leaky ReLU처럼 zero-mean의 출력을 내지만 Saturation 관점에서는 ReLU의 특성도 갖습니다.

    ![](https://i.imgur.com/kHinhTl.png)

6. **Maxout**은 앞서 나온 activation function과는 다른 성격의 함수입니다. Saturated Regime이 없으며 gradient가 0이 되는 지점이 없다는 장점이 있습니다. 하지만 parameter 수가 두배가 된다는 단점이 있습니다.

    ![](https://i.imgur.com/RVQ36kg.png)












* 오버피팅일 경우 어떻게 대처해야 할까요?  

Keyword : Data augmentation, Dropout, parameter Norm Penalties, Batch Normalization, Early stopping

1. Data augmentation

    training data의 개수를 인위적으로 늘려 data의 양을 늘리는 기법입니다. 데이터의 특징을 고려해 사용해야 합니다.



2. parameter Norm penalties

    cost function에 제곱을 더하거나 ($L2$)  절대값을 더하여 ($L1$) weight의 크기에 제한을 줍니다.
    - L2 weight decay(제곱값) : $L2$ parameter 는 ridge 회귀분석 또는 tikhonv 정규화로 알려져있습니다.

    - L1 weight decay(절대값) : LASSO는 선형모델의 $L1$패널티와 최소제곱법(LSM)을 합친 모델입니다.


3. Dropout

    계층마다 일정 비율의 뉴런을 랜덤하게 골라 drop 시키고 나머지 뉴런을 학습하는 방법입니다. dropout을 통해 앙상블 학습처럼 마치 여러 모델을 학습시킨 것과 같은 효과를 주어 오버피팅을 해결할 수 있습니다.

    ![](https://i.imgur.com/zVHFTkS.png)



4. Noise Rubustness

    노이즈나 이상치(outlier) 같은 엉뚱한 데이터가 들어와도 흔들리지 않는 모델(=강건성 있는 모델)을 만들기 위한 방법으로 일부러 노이즈를 주는 방법입니다.

    ![](https://i.imgur.com/at6Z46N.png)

5. Batch Normalization

    활성화 값이 적절하게 분포되도록 하는 값을 좋은 가중치의 초기 값으로 봅니다.
    가중치의 초기값에 의존하지 않고 활성화 값을 강제로 적절히 분포되도록 하는 것을 **배치 정규화(Batch Normalization)** 이라고 합니다.

    ![](https://i.imgur.com/jPnToAx.png)

6. Early stopping

    Epoch가 늘어날수록 Training Error는 줄어들지만, Testing Error는 증가하며 overfitting이 발생할 수 있습니다. 따라서 이전 Epoch에 비해 오차(Error)가 증가하면 오버피팅이 발생하기 전에 학습을 멈추는 방법입니다.

    ![](https://i.imgur.com/lHlJQH7.png)


### [Machine Learning]

* dimension reduction기법으로 보통 어떤 것들이 있나요?

    1. 피쳐 추출(Feature Extraction) : 높은 차원의 row feature들을 더 필요한 요소로 추출하는 기법입니다.
        - 피쳐추출 방법 : PCA,LDA,NMF,SVD 등..

    2. 피쳐 선택(Feature Selection) : 모든 feature 중 필요한 것만 선택하는 기법입니다.
        - 피쳐선택 방법 : Filtering, wrapper, Embedded 등..
        



* PCA는 차원 축소 기법이면서, 데이터 압축 기법이기도 하고, 노이즈 제거기법이기도 합니다. 왜 그런지 설명해주실 수 있나요?  

    PCA(Priciple Component Analysis)는 입력 데이터의 공분산행렬을 기반으로 고유벡터를 생산하고 이렇게 구한 고유벡터에 입력데이터를 선형 변환하여 차원을 축소하는 방법입니다. 차원은 곧 입력데이터의 피쳐를 뜻하므로 데이터 압축 기법으로 볼 수 있습니다.

    또한 PCA는 고유값이 가장 큰, 즉 데이터의 분산이 가장 큰 순으로 주성분 벡터를 추출하는데, 가장 나중에 뽑힌 벡터보다 가장 먼저 뽑힌 벡터가 데이터를 더 잘 설명할 수 있기 때문에 노이즈 제거 기법이라고도 불립니다.

### [Network]

* TCP와 UDP의 헤더를 비교해주세요.  

    https://github.com/Boostcamp-JoHan4Park/Interview-Study/blob/master/junhyuk/3%EC%A3%BC%EC%B0%A8/3%EC%A3%BC%EC%B0%A8_network.pdf
* TCP의 3-way-handshake와 4-way-handshake를 비교 설명해주세요.  

    https://github.com/Boostcamp-JoHan4Park/Interview-Study/blob/master/junhyuk/3%EC%A3%BC%EC%B0%A8/3%EC%A3%BC%EC%B0%A8_network.pdf

### [Operating System]

* 뮤텍스와 세마포어의 차이를 설명해주세요.  

    뮤텍스 : 한 쓰레드, 프로세스에 의해 소유될 수 있는 Key를 기반으로 한 상호배제기법

    세마포어 : signaling mechanism. 현재 공유자원에 접근할 수 있는 쓰레드, 프로세스의 수를 나타내는 값을 두어 상호배제를 달성하는 기법.

    뮤텍스와 세마포어의 차이 : 세마포어는 공유자원에 세마포의 변수만큼의 프로세스(또는 쓰레드)가 접근할 수 있습니다. 반면에 뮤텍스는 오직 1개만의 프로세스(또는 쓰레드)만 접근할 수 있습니다.

    현재 수행중인 프로세스가 아닌 다른 프로세스가 세마포어를 해제할 수 있습니다. 하지만 뮤텍스는 락을 획득한 프로세스가 반드시 그 락을 해제해야 합니다.

* 스케줄러가 무엇이고, 단기/중기/장기로 나누는 기준에 대해 설명해주세요.  

    **스케줄러** 란 OS 내에서 프로세스에게 CPU 위에서 실행될 수 있도록 제어해주는 프로그램 입니다.

    https://github.com/Boostcamp-JoHan4Park/Interview-Study/blob/master/junhyuk/3%EC%A3%BC%EC%B0%A8/3%EC%A3%BC%EC%B0%A8_OS.pdf


### [Database]

* key 정리
    * Candidate Key  
    * Primary Key  
    * Alternate Key  
    * Super Key  
    * Foreign Key  

    https://github.com/Boostcamp-JoHan4Park/Interview-Study/blob/master/junhyuk/3%EC%A3%BC%EC%B0%A8/3%EC%A3%BC%EC%B0%A8_DB.pdf

* SQL Join (join이란? join 종류)

    https://github.com/Boostcamp-JoHan4Park/Interview-Study/blob/master/junhyuk/3%EC%A3%BC%EC%B0%A8/3%EC%A3%BC%EC%B0%A8_DB.pdf

### [Algorithm]

* 시간, 공간 복잡도

    시간 복잡도 : big - O 에 대한 시간개념으로 알고리즘의 수행시간이 얼마인지를 나타냅니다. 알고리즘의 실행순서를 따라가며 Elementory Operation이 일어나는 수를 측정합니다.

    공간 복잡도 : 공간에 대한 개념으로 알고리즘이 공간을 얼마나 필요로 하는지 나타냅니다. 크기가 N인 배열을 만든다고 가정하면 공간 복잡도가 $O(N)$이 되고, $N*N$인 배열을 만든다면 $O(N^2)$이 됩니다. 함수의 재귀적인 호출인 경우 스택 공간도 고려해야 합니다.


* Sort Algorithm  
    * Bubble Sort  
    * Selection Sort  
    * Insertion Sort  
    * Merge Sort  
    * Heap Sort  
    * Quick Sort  
    * Counting Sort  
    * Radix Sort  

    어우.. 정리 못하겠당.. https://github.com/Jay-Ppark/ai-tech-interview/blob/main/answers/8-algorithm.md#2-1