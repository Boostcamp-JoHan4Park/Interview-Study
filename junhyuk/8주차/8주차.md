* 통계에서 사용되는 bootstrap의 의미는 무엇인가요.  

현재 표본에서 추가적으로 표본을 복원 추출하고 각 표본에 대한 통계량을 다시 계산하는 것입니다. 1억 개의 모집단에서 뽑은 200개의 표본이 있다고 합시다. 200개로만 통계량을 구하는 것이 아니라 200개를 기준으로 복원 추출하여 새로운 통계량을 구하는 것입니다.

* 모수가 매우 적은 (수십개 이하) 케이스의 경우 어떤 방식으로 예측 모델을 수립할 수 있을까요? 

비모수적 통계기법을 활용하여 예측 모델을 수립할 수 있습니다. 비모수적 방법은 모집단 분포에 대한 가정 없이 접근하는 방식이기에 모수를 활용하지 않습니다.

* 베이지안과 프리퀀티스트 간의 입장차이를 설명해주실 수 있나요?  

빈도주의자는 모델에 대한 참값이 있으며, 임의로 발생하는 것은 데이터라고 생각합니다. 모델의 파라미터에 대한 참값이 있으며, 데이터가 랜덤으로 주어지는 것이므로 데이터에 대해서 이를 가장 잘 설명할 수 있는 하나의 모델을 찾아야 합니다.

베이지안에서는 데이터가 참값이 있으며 이를 가장 잘 설명하는 모델을 선택합니다. 주사위 모델에 대한 참값이 있다는 빈도주의자와는 달리 베이지안에서는 주사위 모델에 대한 다양한 모델이 있으며 가장 잘 설명할 수 있는 것을 선택합니다.

* Local Minima 문제에도 불구하고 딥러닝이 잘 되는 이유는?  

이전에는 weight와 bias를 random하게 initialize하였지만 weight와 bias를 잘 초기화 시키는 방법(pre-training by RBM, dA)가 제시되었습니다. pre-training을 통해서 효과적으로 layer를 쌓고 여러개의 hidden layer도 효율적으로 훈련시킬수 있게 되었기 때문에 딥러닝이 좋은 성능을 나타내고 있습니다.


  * GD가 Local Minima 문제를 피하는 방법은?
Momentum을 적용하면 관성을 이용하여 학습 속도를 더 빠르게 하고 변곡점을 잘 넘어갈 수 있도록 해주는 역할을 수행합니다.

  * 찾은 해가 Global Minimum인지 아닌지 알 수 있는 방법은?

scheduler를 이용한 다양한 실험으로 결과론적 해석..?
  
* Training 세트와 Test 세트를 분리하는 이유는? 

과적합을 방지하기 위해서입니다;.

  * Validation 세트가 따로 있는 이유는?  

모델의 성능을 평가하기 위해서입니다.

  * Test 세트가 오염되었다는 말의 뜻은?  
  * Regularization이란 무엇인가?  

* 머신러닝(machine)적 접근방법과 통계(statistics)적 접근방법의 둘간에 차이에 대한 견해가 있나요?  
* 인공신경망(deep learning이전의 전통적인)이 가지는 일반적인 문제점은 무엇일까요?  
* 지금 나오고 있는 deep learning 계열의 혁신의 근간은 무엇이라고 생각하시나요?  